{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "# Normal imports â€” assume parser.py and chunker.py live in your root or package\n",
    "from modules.vectors.components.parser import MarkdownNoteParser\n",
    "from modules.vectors.components.chunker import chunk_elements\n",
    "\n",
    "BASE_DIR = Path().cwd()\n",
    "MD_PATH = BASE_DIR / \"artifacts\" / \"test_md.md\"\n",
    "ARTIFACTS_DIR = Path(\"./artifacts\").resolve()\n",
    "RECON_DIR = ARTIFACTS_DIR / \"reconstructed\"\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RECON_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# @pytest.mark.skipif(not VAULT_PATH.exists(), reason=\"Vault path does not exist\")\n",
    "def test_chunk_vault_to_dataframe():\n",
    "    parser = MarkdownNoteParser()\n",
    "    md_path = MD_PATH\n",
    "    all_rows = []\n",
    "    \n",
    "    elements = parser.parse_markdown_file(md_path)\n",
    "    chunks = chunk_elements(\n",
    "        elements,\n",
    "        doc_name=md_path.name,\n",
    "        doc_path=str(md_path),\n",
    "        max_tokens=900,\n",
    "        overlap=150,\n",
    "    )\n",
    "    for c in chunks:\n",
    "        all_rows.append({\n",
    "            \"file\": str(md_path),\n",
    "            \"index\": c[\"metadata\"][\"chunk_index\"],\n",
    "            \"chunk_id\": c[\"chunk_id\"],\n",
    "            \"tokens\": c[\"tokens\"],\n",
    "            \"headings\": \" / \".join(c.get(\"heading_path\", [])),\n",
    "            \"text\": c[\"text\"],\n",
    "        })\n",
    "    \n",
    "    recon = \"\\n\\n\".join(ch[\"text\"] for ch in sorted(chunks, key=lambda z: z[\"metadata\"][\"chunk_index\"]))\n",
    "    (RECON_DIR / f\"{md_path.stem}.reconstructed.md\").write_text(recon, encoding=\"utf-8\")\n",
    "\n",
    "    df = pd.DataFrame(all_rows).sort_values([\"file\", \"index\"]).reset_index(drop=True)\n",
    "    df.to_csv(ARTIFACTS_DIR / \"chunks.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    \n",
    "    assert not df.empty\n",
    "    #assert df[\"tokens\"].max() <= 900\n",
    "\n",
    "    print(f\"\\nVault: {MD_PATH}\")\n",
    "    print(f\"Chunks: {len(df)}\")\n",
    "    print(f\"CSV saved to {ARTIFACTS_DIR / 'chunks.csv'}\")\n",
    "    print(f\"Reconstructions saved to {RECON_DIR}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_chunk_vault_to_dataframe()\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
